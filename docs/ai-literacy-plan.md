Sitemap & Navigation
Home (Welcome, how to use site)

Modules (index page with tiles for each)

Module 1: What Is AI?

Module 2: Data & Bias

Module 3: AI Outputs & Reliability

Module 4: Attribution & Academic Integrity

Module 5: Privacy & Safety

Module 6: Responsible Use in Coursework

Game: AI Scenario Challenge

Resources (glossary, citations, accessibility info)

About & Contact

Module Outlines (10–15 minutes each, consistent template)
Template fields: Overview, Learning Objectives (3), Core Concepts (bullets), Worked Example, Common Mistake, Quick Check (3 Q/A), Disclosure & Citation Guidance.

Module 1: What Is AI?
Learning Objectives: define AI in plain language; distinguish rules-based vs. learned systems; identify everyday AI examples.

Core Concepts: AI vs. traditional software; machine learning basics; narrow vs. general AI; prediction vs. decision.

Worked Example: Compare a programmed calculator vs. a spam filter that learns from labeled emails.

Common Mistake: Assuming all AI “thinks” like humans rather than following statistical patterns.

Quick Check (A):

Q: What makes an AI system “learn”? A: It adjusts parameters based on data/feedback.

Q: What is narrow AI? A: An AI built for a specific task (e.g., translation).

Q: Is a thermostat AI? A: Usually no—fixed rules, no learning.

Disclosure & Citation: Always state when AI tools informed your work; cite tool name/version, date, and your prompts.

Module 2: Data & Bias
Learning Objectives: explain training data role; identify bias sources; describe how to mitigate bias.

Core Concepts: datasets, labels, sampling bias, representation, feedback loops.

Worked Example: Image classifier trained mostly on daylight photos underperforms at night; balanced data improves results.

Common Mistake: Believing more data alone fixes bias without considering representation quality.

Quick Check (A):

Q: What is sampling bias? A: When collected data misrepresents the target population.

Q: One mitigation? A: Balance data across key attributes.

Q: Feedback loop example? A: Biased predictions influence future data collection.

Disclosure & Citation: Note dataset provenance if known; when reporting results, describe data limits and cite sources.

Module 3: AI Outputs & Reliability
Learning Objectives: evaluate AI-generated content; identify hallucinations; apply verification steps.

Core Concepts: confidence vs. correctness; hallucinations; retrieval vs. generation; verification workflows.

Worked Example: Chatbot provides a fabricated citation; student cross-checks in library database and replaces with real source.

Common Mistake: Trusting confident-sounding outputs without independent verification.

Quick Check (A):

Q: What is a hallucination? A: AI outputs that are fabricated or unsupported.

Q: First verification step? A: Check against trusted sources.

Q: Does tone indicate accuracy? A: No—style is not evidence.

Disclosure & Citation: Mark AI-generated text; cite checked sources, not the hallucinated ones; include your verification notes.

Module 4: Attribution & Academic Integrity
Learning Objectives: describe when AI assistance must be disclosed; format citations; differentiate permissible vs. impermissible use.

Core Concepts: institutional policies; citation formats for AI; collaboration boundaries; originality.

Worked Example: Student uses AI to brainstorm outline, then cites the tool in acknowledgments and marks AI-assisted sections.

Common Mistake: Omitting AI disclosure because “I edited it later.”

Quick Check (A):

Q: When must AI use be disclosed? A: Whenever AI meaningfully contributed to ideas or wording.

Q: What belongs in an AI citation? A: Tool name/version, date, prompt context.

Q: Is submitting AI-written code as your own allowed? A: Typically no—check course policy.

Disclosure & Citation: Follow course policy; use consistent citation style (e.g., APA/MLA) for AI tools; keep prompt logs.

Module 5: Privacy & Safety
Learning Objectives: identify sensitive information; apply safe prompting; understand data retention risks.

Core Concepts: PII/PHI; prompt safety; data retention and model training; access controls.

Worked Example: Avoid entering classmates’ emails into a public AI tool; instead, use placeholders or local tools.

Common Mistake: Sharing sensitive data assuming the tool “forgets.”

Quick Check (A):

Q: What is PII? A: Personally identifiable information.

Q: Safe alternative to real names? A: Use placeholders or anonymized data.

Q: Do all tools retrain on your prompts? A: No—varies by provider; check policy.

Disclosure & Citation: Note when data was anonymized; state if AI tool retains prompts; cite provider privacy policy if referenced.

Module 6: Responsible Use in Coursework
Learning Objectives: choose appropriate AI use cases; structure prompts ethically; reflect on impact.

Core Concepts: task fit (ideation vs. final work); guardrails in prompts; reflection logs; collaboration etiquette.

Worked Example: Student uses AI to draft study questions, then manually writes answers and documents AI’s role.

Common Mistake: Using AI for graded deliverables without understanding allowed scope.

Quick Check (A):

Q: Good use case example? A: Brainstorming study questions.

Q: Guardrail in a prompt? A: “Do not fabricate sources—if unsure, say so.”

Q: Why keep a reflection log? A: To track how AI influenced your work and ensure integrity.

Disclosure & Citation: Document allowed vs. disallowed uses; cite AI contributions; include your own verification/reflection notes.

Game Spec: “AI Scenario Challenge”
Format: Browser-based, 10 short scenarios; each scenario offers 2–4 choices.

Scoring Dimensions: Accuracy (correctness/use of evidence), Attribution (crediting sources/AI), Privacy (protection of sensitive info).

Rules:

Player starts at 0 in each dimension.

Each choice adjusts one or more dimensions (+1, 0, or -1).

After 10 scenarios, show totals and brief feedback per dimension (e.g., “Great at Attribution; watch Privacy”).

UI Flow:

Intro screen: explains dimensions and scoring.

Scenario card: text + choices; player selects one; immediate feedback with dimension deltas.

Score ribbon: persistent mini-bar for A/A/P.

Summary screen: totals, per-dimension tips, option to replay.

Minimal Controls: Next/Back (Back disabled after answering to avoid farming scores), Replay.

Accessibility: keyboard navigation, clear focus states, plain-language explanations, captions for any media.